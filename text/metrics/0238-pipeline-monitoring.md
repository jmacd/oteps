# OpenTelemetry Telemetry Pipeline metrics

Propose a uniform standard for telemetry pipeline metrics generated by
OpenTelemetry SDKs and Collectors.

## Motivation

OpenTelemetry desires to standardize conventions for the metrics
emitted by SDKs about success and failure of telemetry reporting. At
the same time, the OpenTelemetry Collector has existing conventions
which are expected to connect with metrics emitted by SDKs and have
similar definitions.

## Explanation

This document proposes two metric instrument semantics threefour
overall metric instruments for pipeline accounting, considering SDK
and Collector pipeline metrics as separate, non-intersecting signals
for reasons discussed below.  The three instruments are:

- `otelcol_produced_items`: Exported, dropped, and discarded items (Collector)
- `otelcol_consumed_items`: Received and inserted data items (Collector)
- `otelsdk_produced_items`: Exported, dropped, and discarded items (SDK)

The fourth instrument, named `otelsdk_consumed_items`, is logically
well-defined by this proposal, but not necessary or useful, for
SDK-specific reasons discussed below.

We use the term "pipeline" to describe a directional arrangement of
system components which produce, consume, and process telemetry on its
way from the point of origin to the endpoint(s) in its journey.
Pipeline components included in this specification are:

- OpenTelemetry SDKs: As telemetry producers, these components are the
  start of a pipeline.  These components also 
- OpenTelemetry Collectors: The OpenTelemetry collector contains an
  arrangement of components which act as both consumers and producers.
  
The terms "following"/"follower" and "preceding"/"preceder" refer to
the relative components after or before another component in a
pipeline.  The preceding component ("preceder") produces data that is
consumed by the following component ("follower").

An arrangement of pipeline components acting as a single unit, such as
implemented by the OpenTelemetry Collector, is called a segment.  Each
segment consists of a receiver, zero or more processors, and an
exporter.  The terms "following" and "preceding" apply to pipeline
segments with the same meaning as for components.  For example, a
agent pipeline segment forwards to a gateway pipeline segment.

## Detailed design

### Producer and Consumer instruments

We choose to specify two metric instruments for use counting outcomes,
one instrument to account for producer outcomes and one to account for
consumer outcomes.  In an ideal pipeline, a conservation rule exists
between what goes in (i.e., is consumed) and what goes out (i.e., is
produced).  The use of producer and consumer metric instruments is
designed to enable consistency checks between producer and consumer
metrics within and between adjacent pipeline segments.  When the
pipeline is properly functioning and instrumented, we expect the sum
of producer and consumer item counts across all outcomes to be equal.

The alternative, which uses one metric instrument per producer outcome
and one metric instrument per consumer outcome, has known
difficulties.  To define a ratio between any one outcome and the total
requires a metric formula defined by all the outcomes.  On other hand,
it is common practice using OpenTelemetry metrics to aggregate by
attribute.  It is easier and more convenient, when a single metric
instrument is used with an attribute for distinct outcomes, to define
ratios and build area charts from the resulting data.

The use of per-outcome counters is also logically confusing.  For
example, existing OpenTelemetry collector metrics for exporters have
both `sent` and `send_failed` metrics.  However, `sent` only counts
success outcomes. A user could easily believe that the failure ratio
is defined as `send_failed / sent`, since (logically) something has to
be sent before the send can fail.  The correct failure ratio, using
exclusive counters, is `send_failed / (sent + send_failed)`, but from
experience, users can easily miss this detail.  Moreover, when
exclusive counters have been defined in this manner, it is impossible
to define new outcomes, as every formula would need to be updated.

### Processors count as producers and consumers

As specified, processors are responsible for counting items only when
the number changes while passing through a processor.  Processors are
responsible for counting producer outcomes when they remove an item of
telemetry from a request, including:

- `discarded` outcomes, which do not pass the data and return success
- `dropped` outcomes, which do not pass the data and return failure.

Data that passes through a processor component, otherwise, should not
be counted as produced because following components are responsible
for counting the outcome.  Considering the combined producer outcomes
for a pipeline segment, the total will include `discarded` and
`dropped`, subtotals from processors combined with all potential
outcomes from the exporter component.

Data that is inserted by a processor component, meaning new items of
telemetry that were not consumed from the preceding component in the
pipeline, should be counted as consumer outcomes by the component that
inserted them, since the preceding component does not know about them.
Processors that insert items will:

1. Wait until the next component returns from the Consume() operation.
   (If the processor does not wait, it will use add `deferred:` to the
   outcome, see below.)
2. Count a consumer outcome according to the return value for the
   number of points inserted.
   
By these rules, a processor that inserts data and then immediately
drops or discards the same data will raise the count equally for both
both consumer and producer metric instruments.

### Distinct prefixes for SDKs and Collectors

There is a potential to use the same metric names to describe SDK
producers/consumers and Collector producers/consumers.  However, we
find two reasons this unification step should be avoided.

First, we seek to avoid aggregations combining first-class SDKs
producers, SDK consumer components (i.e., bridges) and Collector
producers, which do not have corresponding consumer metrics, and
Collector producers.

Second (really a specific case of the first), we seek to avoid
aggregations that combine OpenTelemetry Collector pipeline metrics
with SDK pipeline metrics in the same process, when the OpenTelemetry
SDK instruments the OpenTelemetry Collector.

### Collector outcomes are asymmetric

There are a several of reasons why the producer and consumer outcomes
counted by Collector pipeline monitoring will reflect contradictory
information.

For example, when timeouts are configured independently, as for
example when a preceding segment's timeout is smaller than a following
stage's timeout.  The preceding exporter's timeout, if less than the
following exporter's timeout may cause consumer `timeout` outcomes
without corresponding producer `timeout` outcomes.

### Deferred outcomes

In some configurations, Collector pipeline segments have asynchronous
elements, in an arrangement where the `Consume()` operation called by
the preceder on the follower returns success, and responsibility for
delivery transfers to the follower.  When deferred outcomes are in
use, consumer metrics will generally indicate 100% `accepted`
outcomes.

For these cases, exporters are expected to use the `deferred:` outcome
categories to signal to monitoring systems especially the failure 
outcomes that were not seen by producers.

### Resource-exhausted case

The `exhausted` outcome is meant to map to the gRPC RESOURCE_EXHAUSTED
status code and the HTTP 429 status code.  These codes are special and
distinct from the general-purpose `retryable` outcome because:

- The failures they represent should generally be excluded in
  calculating service-level objectives.  When these error codes are
  returned, it is the caller's responsibility to remediate.
- This outcome may lead to specifically different load-balancer
  behavior, so it is an important signal for monitoring pipeline
  health.

## Pipeline equations

The behavior of a pipeline section consisting of one or more elements
can be reduced to distinct operation categories.

The consumer categories, leading to the first pipeline segment equation:

- **Received**: An item of telemetry was exported from a preceding pipeline segment
- **Inserted**: An item of telemetry was inserted by this pipeline segment

The first equation:

```
Consumed(Segment) == Recieved(Segment) + Inserted(Segment)
```

The producer categories, leading to the second pipeline segment equation:

- **Exported**: An attempt was made to export the telemetry to a following pipeline segment
- **Discarded**: Considered success, an item of telemetry was eliminated (i.e., export never attempted)
- **Dropped**: Considered failure, an item of telemetry was eliminated (i.e., export never attempted)

The second equation:

```
Produced(Segment) == Discarded(Segment) + Dropped(Segment) + Exported(Segment)
```

The third equation states that the sum of all items-consumed outcomes
for a pipeline segment equals the sum of all items-produced outcomes
for that segment.

```
Consumed(Segment) == Produced(Segment)
```

#### Invariant checking

In order to use these equations exactly as written, it is important to
recognize that consumer and producer accounting is independent and
that these signals can lead or lag each order, depending on pipeline
configuration.

The simplest way to check the invariants, therefore, is to "drain" the
pipeline so that it is empty, meaning all items have been accounted
for.  For the OpenTelemetry Collector, therefore, it should be
possible to verify this and warn about improper accounting during
shutdown.

These equations allow are useful in the abstract, because , without ordering
requirements.  After a pipeline has been drained and the individual
components shut down, we expect the producer and consumer instrument
values to match exactly.

### Measuring pipeline loss

Considering an Exporter and Receiver pair connecting two OpenTelemetry
Collector pipeline segments, we expect ideally the number exported to
match the number received.

```
Exported(Preceder) == Received(Follower)
```

Where Exported and Received counts are defined by the first and second
equations above, noting that Exported excludes Dropped or Discarded
outcomes.

We can make additional inferences based on the individual outcomes to
provide additional insights when they do not match.  For example, the
`exhausted`, `rejected` and `accepted` outcomes reflect responses that
the receiver definitely gave, as opposed to `retryable` and `timeout`
which are ambiguous.

```
Exported_Responded(Segment) == Exported(Segment) - Retryable(Segment) - Timeout(Segment)
```

In a real pipeline, therefore, we expect:

```
Exported_Responded(Preceder) <= Received(Follower) <= Exported(Preceder)
```

When an observability platform detects an out-of-range value, there is
likely to be a defective pipeline or missing instrumentation.

## SDK-specific considerations

OpenTelemetry SDKs receive telemetry from multiple components.  In
addition to telemetry originating from OpenTelemetry APIs,
signal-specific bridges also insert telemetry into the SDK pipeline.

The asymmetry between exporter and receiver outcomes that is seen for
Collectors is not a consideration for SDKs, because [OpenTelemetry
APIs _by definition_ do not return errors to the
caller](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/library-guidelines.md#api-and-minimal-implementation).

The use of a consumer metric instrument is not specified for SDKs,
even though it can be meaningfully defined, because of there is no
meaningful asymmetry in SDK pipelines.  When consumer outcomes do not
matter, producer outcomes tell the whole story.  For this reason,
there is no `otelsdk_consumed_items` in this proposal.

Similarly, SDKs are not meant to use the `deferred:` outcome prefix,
as there is not a meaningful distinction to be made.

Like the OpenTelemetry Collector, SDK pipelines may discard (e.g., by
Sampling), drop (e.g., because queue-full).  Note that this proposal
means counting Spans that are discarded due to sampling, in the
SDK producer metric instrument.

## Metric instrument summary

The specified counter names are:

- `otelcol_consumed_items`: The number of items received or inserted into a pipeline.
- `otelcol_produced_items`: The number of items discarded, dropped, or exported by a Collector pipeline segment.
- `otelsdk_produced_items`: The number of items discarded, dropped, or exported by a SDK pipeline segment.

### Recommended conventional attributes

- `otel.success` (boolean): This is true or false depending on whether the
  outcome is considered success or a failure.  See the chart below.
- `otel.outcome` (string): This describes the outcome in a more specific
  way than `otel.success`, with recommended values specified below.
- `otel.signal` (string): This is the name of the signal (e.g., "logs",
  "metrics", "traces")
- `otel.component` (string): Name of the component in a pipeline.
- `otel.pipeline` (string): Name of the pipeline, to distinguish multiple 

### Specified `otel.outcome` attribute values

The `otel.outcome` attribute indicates extra information about a
success or failure, with a fixed list of possible values specified for
the attribute.

The outcomes corresponding with `otel.success=true`

- `accepted`: Indicates a normal, synchronous request success case.
  The item was consumed by the next stage of the pipeline, which
  returned success.  Note the item could have been deferred by a
  subsequent component, but as far as this component knows, the 
  request successful.
- `discarded`: Indicates a successful outcome in which the next stage
  of the pipeline does not handle the event, as by a sampling
  processor.
- `deferred:<failure outcome>`: Deferred cases are where the
  caller receives a success response and the true outcome is failure,
  but this is not known until later.  The item is counted as
  `deferred:` combined with the failure outcome that would otherwise
  have been counted.

For `otel.success=false`, transient and potentially retryable cases:

- `dropped`: The component introduced an original failure and did not
  send to the next stage in the pipeline.
- `timeout`: The item was in the process of being sent but the request
  timed out, or its deadline was exceeded.  In this case, it
  undetermined whether the consuming pipeline saw the item or not.
- `exhausted`: The item was handled by the next stage of the pipeline,
  which returned an error code indicating that it was overloaded.  If
  the resource being exhausted is local and the item was not handled
  by the next stage of the pipeline, record the item `dropped` and
  return a resource-exhausted status code to the producer, who will
  record a `exhausted` outcome.
- `retryable`: The item was handled by the next stage of the pipeline,
  which returned a retryable error status not covered by any of the
  above values.

For success=false, permanent cases:

- `rejected`: The item was handled by the next stage of the pipeline,
  which returned a permanent error status or partial success status
  indicating that some items could not be accepted.
- `unknown`: May be used when the component is suppressing errors and
  not actually counting successes and failures.  As a special case,
  the outcome `deferred:unknown` indicates that a success response 
  was given and no information about the actual outcome is available.

### Success, Outcome matrix

| Outcome            | Consume Attempted? | Consume Success? | `otel.success` | Meaning                                                       |
|--------------------|--------------------|------------------|----------------|---------------------------------------------------------------|
| accepted           | true               | true             | true           | Data (successfully) sent                                      |
| discarded          | false              | true             | true           | Data (successfully) discarded                                 |
| dropped            | false              | false            | false          | Request never started, error returned                         |
| timeout            | true               | false            | false          | Request started, timed out, error returned                    |
| exhausted          | true               | false            | false          | Request started, insufficient resources, error returned       |
| retryable          | true               | false            | false          | Request started, retryable error status, error returned       |
| rejected           | true               | false            | false          | Request completed, permanent error status, error returned     |
| deferred:dropped   | false              | true             | false          | Request never started, error NOT returned                     |
| deferred:timeout   | true               | true             | false          | Request started, timed out, error NOT returned                |
| deferred:exhausted | true               | true             | false          | Request started, insufficient resources, error NOT returned   |
| deferred:retryable | true               | true             | false          | Request started, retryable error status, error NOT returned   |
| deferred:rejected  | true               | true             | false          | Request completed, permanent error status, error NOT returned |
| deferred:unknown   | true               | true             | false          | Request has unknown outcome, error NOT returned               |

#### Examples of each outcome

##### Success, Accepted

This is the common success case.  The item(s) were sent to the
consumed by the follower in the pipeline and the result was success.
It does not matter whether the request was deferred or not when
telemetry is `accepted`.

##### Success, Discarded

A processor was configured with instructions not to pass certain data.
For example, a sampler or a filter processor that decides not to pass
an item for any reason, when it is considered success.

##### Dropped and Deferred-Dropped

(If deferred: A component returned success to its preceder, then ...)

The component never sent the item(s) due to limits in effect.  For
example, shutdown was ordered and the queue could not be drained in
time due to a limit on parallelism.

##### Timeout and Deferred-Timeout

(If deferred: A component returned success to its preceder, then ...)

The component attempted sending the item(s), and the item(s) did not
succeed before the deadline expired or the timeout elapsed.

##### Exhausted and Deferred-Exhausted

(If deferred: A component returned success to its preceder, then ...)

The component attempted sending the item(s), and the consumer
indicated its (or its consumers') resources were exceeded.

##### Retryable and Deferred-Retryable

(If deferred: A component returned success to its preceder, then ...)

The component attempted sending the item(s), and the response was some
kind of retryable condition not covered by `timeout` or `exhausted`.
This could be host unavailable, for example.

##### Rejected and Deferred-Rejected

(If deferred: A component returned success to its preceder, then ...)

The component attempted sending the item(s), but the response was some
kind of non-retryable condition.  This could be host access denied,
for example.

##### Deferred-Unknown

A component returned success to its preceder, then the component
attempted sending the item(s), and that is all we know.

### Example scenarios

WIP Include some common scenarios covering exporterhelper,
batchprocessor, memorylimiter, etc.
